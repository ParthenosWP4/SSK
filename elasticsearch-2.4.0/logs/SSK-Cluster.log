[2018-08-27 10:09:25,996][INFO ][node                     ] [Ashcan] version[2.4.0], pid[54106], build[ce9f0c7/2016-08-29T09:14:17Z]
[2018-08-27 10:09:25,998][INFO ][node                     ] [Ashcan] initializing ...
[2018-08-27 10:09:27,063][INFO ][plugins                  ] [Ashcan] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-08-27 10:09:27,090][INFO ][env                      ] [Ashcan] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [21.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2018-08-27 10:09:27,090][INFO ][env                      ] [Ashcan] heap size [989.8mb], compressed ordinary object pointers [true]
[2018-08-27 10:09:27,091][WARN ][env                      ] [Ashcan] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2018-08-27 10:09:28,685][INFO ][node                     ] [Ashcan] initialized
[2018-08-27 10:09:28,685][INFO ][node                     ] [Ashcan] starting ...
[2018-08-27 10:09:28,754][INFO ][transport                ] [Ashcan] publish_address {127.0.0.1:9300}, bound_addresses {[fe80::1]:9300}, {[::1]:9300}, {127.0.0.1:9300}
[2018-08-27 10:09:28,769][INFO ][discovery                ] [Ashcan] SSK-Cluster/BwJBXCvDQoC0nVGJU6UU5Q
[2018-08-27 10:09:31,803][INFO ][cluster.service          ] [Ashcan] new_master {Ashcan}{BwJBXCvDQoC0nVGJU6UU5Q}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2018-08-27 10:09:31,814][INFO ][http                     ] [Ashcan] publish_address {127.0.0.1:9200}, bound_addresses {[fe80::1]:9200}, {[::1]:9200}, {127.0.0.1:9200}
[2018-08-27 10:09:31,815][INFO ][node                     ] [Ashcan] started
[2018-08-27 10:09:31,852][INFO ][gateway                  ] [Ashcan] recovered [1] indices into cluster_state
[2018-08-27 10:09:32,512][INFO ][cluster.routing.allocation] [Ashcan] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][3]] ...]).
[2018-08-27 10:17:27,449][INFO ][cluster.metadata         ] [Ashcan] [ssk] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2018-08-27 10:17:27,505][INFO ][cluster.routing.allocation] [Ashcan] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][4]] ...]).
[2018-08-27 10:17:27,552][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [resource_metadata]
[2018-08-27 10:17:27,566][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:17:27,573][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:17:27,579][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:17:27,585][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:17:27,593][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:17:27,600][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:17:27,610][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [resource]
[2018-08-27 10:17:27,617][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource]
[2018-08-27 10:17:27,628][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource]
[2018-08-27 10:17:27,639][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [step_metadata]
[2018-08-27 10:17:27,652][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:17:27,667][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:17:27,677][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:17:27,689][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:17:27,702][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:17:27,711][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:17:27,720][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [scenario_metadata]
[2018-08-27 10:17:27,737][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:17:27,755][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:17:27,769][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:17:27,776][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:17:27,782][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:17:27,788][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:17:27,793][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [step]
[2018-08-27 10:17:27,799][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,804][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,812][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,818][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,824][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,830][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,837][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,853][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,867][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,875][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,883][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:27,893][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [scenario]
[2018-08-27 10:17:27,902][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:17:27,916][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:17:27,930][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:17:27,944][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:17:27,956][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [glossary]
[2018-08-27 10:17:27,967][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [glossary]
[2018-08-27 10:17:27,973][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [glossary]
[2018-08-27 10:17:27,979][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [standard]
[2018-08-27 10:17:28,204][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [standard]
[2018-08-27 10:17:28,637][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [standard]
[2018-08-27 10:17:32,950][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [glossary]
[2018-08-27 10:17:46,286][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:17:46,406][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:17:46,428][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:46,443][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:17:46,463][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:17:47,034][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource]
[2018-08-27 10:17:47,486][DEBUG][action.index             ] [Ashcan] failed to execute [index {[ssk][step][AWV6ddXb38wE0cQHwucw], source[{"TEI":{"type":"researchStep","id":"step_DoDaAGftRC","teiHeader":{"fileDesc":{"titleStmt":{"title":"step_DoDaAGftRC.xml","author":{"persName":"Haaf Susanne","affiliation":"Berlin-Brandenburg Academy of Sciences and Humanities"}},"publicationStmt":{"authority":"Parthenos","availability":{"licence":{"target":"http://creativecommons.org/licenses/by/4.0/","p":"The Creative Commons Attribution 4.0 Unported (CC BY 4.0) Licence applies to this\n       document."}}},"sourceDesc":{"p":"Created from scratch"}},"revisionDesc":{"change":null}},"text":{"body":{"listEvent":{"event":{"type":"researchStep","head":{"type":"stepTitle","lang":"en","content":"Determination of digitization and annotation guidelines\n      for the research corpus"},"desc":[{"type":"definition","lang":"en","content":["Corpus research should be based on interoperable data,\n      i.e. data that was harmonized with regard to transcription and encoding guidelines. Beforehand\n      the harmonization it is necessary to pick or define proper guidelines. For the encoding of\n      structural phenomena of text, it has become best practice in text processing contexts to apply\n      the tagset provided by the Text Encoding Initiative (TEI-P5). However, the TEI tagset as a\n      whole is broad offering tagging solutions for the most various domains. Hence, in order to\n      achieve unambiguous encoding, it has to be reduced and contoured for its intended application.\n      There are TEI formats published for re-use, e.g. those maintained by the TEI consortium, which\n      can be evaluated for possible re-use rather than creating a new format from scratch. With the\n      DTABf, a TEI format has been proposed, that was customized for the encoding of originally\n      written texts of various text types for the purpose of corpus-based work. Its components are: ",{"list":{"item":["Documentation: Guidelines for text annotation","Documentation: Guidelines for text recognition","Schema: Formal specification in ODD and RNG schemas (for print and manuscript\n        annotation)","Schema: Schematron constraints for quality checks beyond the schema"]}}]},{"type":"terms","lang":"en","term":[{"key":"Discovering","source":"http://tadirah.dariah.eu/","type":"activity"},{"key":"Designing","source":"http://tadirah.dariah.eu/","type":"activity"},{"key":"Meta: Assessing","source":"http://tadirah.dariah.eu/","type":"activity"},{"key":"StandardsSpecifications","source":"http://tadirah.dariah.eu/","type":"object"},{"key":"Standards","source":"NEMO","type":"object"},{"key":"XML","source":"standard_list","type":"standard"},{"key":"TEI","source":"standard_list","type":"standard"}]}],"linkGrp":{"type":"generalResources","ref":[{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/T7672NJ8","type":"specification","content":"DTABf website"},{"source":"github","target":"https://github.com/deutschestextarchiv/dtabf/","type":"specification","content":"DTABf source documents"},{"source":"github","target":"https://github.com/deutschestextarchiv/dtabf/tree/master/schema","type":"specification","content":"DTABf ODDs and Schemas"},{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/DVKJRRVU","type":"paper","content":"Haaf/Geyken/Wiegand (2015)"},{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/ZEZE3HV8","type":"paper","content":"Haaf/Thomas (2017)"},{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/8XCAEJXX","type":"blog","content":"\n       Haaf (2017) "},{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/V6NJ5IBX","type":"website","content":"TEI Customizations"}]}}}}}},"position":3,"GithubRef":"step_DoDaAGftRC"}]}] on [[ssk][0]]
MapperParsingException[failed to parse [TEI.text.body.listEvent.event.desc.content]]; nested: IllegalArgumentException[unknown property [list]];
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:329)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:311)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseNonDynamicArray(DocumentParser.java:416)
	at org.elasticsearch.index.mapper.DocumentParser.parseArray(DocumentParser.java:381)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:256)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:124)
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:309)
	at org.elasticsearch.index.shard.IndexShard.prepareCreate(IndexShard.java:529)
	at org.elasticsearch.index.shard.IndexShard.prepareCreateOnPrimary(IndexShard.java:506)
	at org.elasticsearch.action.index.TransportIndexAction.prepareIndexOperationOnPrimary(TransportIndexAction.java:214)
	at org.elasticsearch.action.index.TransportIndexAction.executeIndexRequestOnPrimary(TransportIndexAction.java:223)
	at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:157)
	at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:66)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:648)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:77)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: unknown property [list]
	at org.elasticsearch.index.mapper.core.StringFieldMapper.parseCreateFieldForString(StringFieldMapper.java:366)
	at org.elasticsearch.index.mapper.core.StringFieldMapper.parseCreateField(StringFieldMapper.java:315)
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:321)
	... 41 more
[2018-08-27 10:18:05,378][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:18:05,394][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:18:05,983][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:18:08,276][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource]
[2018-08-27 10:18:08,851][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:18:09,068][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:18:11,126][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:19:21,789][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:19:40,231][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:21:25,652][DEBUG][action.index             ] [Ashcan] failed to execute [index {[ssk][scenario][AWV6eSoU38wE0cQHwuit], source[{"TEI":{"type":"researchScenario","id":"SSK_sc_production3DObjectsScenario","teiHeader":{"fileDesc":{"titleStmt":{"title":"Production and processing of 3D objects","author":[{"persName":"Hélène Gautier","affiliation":"Huma-Num/CNRS"},{"persName":"Adeline Joffres","affiliation":"Huma-Num/CNRS"},{"persName":"Paulin Ribbe","affiliation":"Huma-Num/CNRS"},{"persName":"Mehdi Chayani","affiliation":"3D-SHS Huma-Num's consortium"},{"persName":"Xavier Granier","affiliation":"3D-SHS Huma-Num's consortium"},{"persName":"Sarah Tournon-Valiente","affiliation":"3D-SHS Huma-Num's consortium"}]},"publicationStmt":{"authority":"PARTHENOS","availability":{"licence":{"target":"http://creativecommons.org/licenses/by/4.0/","p":"The Creative Commons Attribution 4.0 Unported (CC BY 4.0) Licence applies to this\n              document."}}},"sourceDesc":{"p":"Created from scratch"}},"revisionDesc":{"change":null}},"text":{"body":{"div":{"type":"scenario","id":"sc_Production_3D_Objects","head":{"type":"scenarioTitle","lang":"en","content":"Production and processing of 3D objects"},"desc":[{"type":"definition","lang":"en","content":["The project aim is to digitize objects at different\n          scale from an artefact to cultural heritage site to help scientific community to\n          visualize, analyze, simulate and synthesize the result of their research. It allows for\n          better comprehension of the case studies. The 3D object is also a powerfull mean to bring\n          out new hypotheses of research. In some cases, producing an \"accurate\" virtual\n          version of cultural heritage site is a mean of preserving it. Those best practices and\n          methods are detailed in the ",{"ref":{"target":"https://hal.archives-ouvertes.fr/hal-01683842","type":"report","content":"3D-SHS consortium white\n            paper"}},"published in 2017, and in the ",{"ref":{"target":"https://hal.inria.fr/PARTHENOS/hal-01526713","type":"report","content":"Parthenos White\n            Paper"}}," \"Digital 3D Objects in Art and Humanities: challenges of creation,\n          interoperability and preservation\""]},{"type":"terms","lang":"en","term":[{"source":"aurehal","type":"discipline","content":"Archaeology and Prehistory"},{"source":"aurehal","type":"discipline","content":"Cultural heritage and museology"},{"key":"Georeferencing","source":"tadirah","type":"techniques"},{"key":"Photography","source":"tadirah","type":"techniques"},{"key":"Preservation Metadata","source":"tadirah","type":"techniques"},{"key":"Scanning","source":"tadirah","type":"techniques"},{"key":"Technology Preservation","source":"tadirah","type":"techniques"},{"key":"Images (3D)","source":"nemo","type":"object"}]}],"figure":{"type":"image","head":null,"graphic":{"url":"https://raw.githubusercontent.com/ParthenosWP4/SSK/master/img/scenario3D.jpg"},"figDesc":null},"listEvent":{"event":[{"ref":"step_A3DOBS","type":"researchStep","id":"s1"},{"ref":"step_A3DOBP","type":"researchStep","id":"s2"},{"ref":"step_3DMtTF","type":"researchStep","id":"s3"},{"ref":"step_3DV","type":"researchStep","id":"s4"}]}}}}},"GithubRef":"SSK_sc_production3DObjectsScenario.xml"}]}] on [[ssk][4]]
MapperParsingException[failed to parse [TEI.text.body.div.desc.content]]; nested: IllegalArgumentException[unknown property [ref]];
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:329)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:311)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseNonDynamicArray(DocumentParser.java:416)
	at org.elasticsearch.index.mapper.DocumentParser.parseArray(DocumentParser.java:381)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:256)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:124)
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:309)
	at org.elasticsearch.index.shard.IndexShard.prepareCreate(IndexShard.java:529)
	at org.elasticsearch.index.shard.IndexShard.prepareCreateOnPrimary(IndexShard.java:506)
	at org.elasticsearch.action.index.TransportIndexAction.prepareIndexOperationOnPrimary(TransportIndexAction.java:214)
	at org.elasticsearch.action.index.TransportIndexAction.executeIndexRequestOnPrimary(TransportIndexAction.java:223)
	at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:157)
	at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:66)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:648)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:77)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: unknown property [ref]
	at org.elasticsearch.index.mapper.core.StringFieldMapper.parseCreateFieldForString(StringFieldMapper.java:366)
	at org.elasticsearch.index.mapper.core.StringFieldMapper.parseCreateField(StringFieldMapper.java:315)
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:321)
	... 38 more
[2018-08-27 10:21:50,950][DEBUG][action.index             ] [Ashcan] failed to execute [index {[ssk][step][AWV6eYzm38wE0cQHwujR], source[{"TEI":{"type":"researchStep","id":"step_EaXswO_150917","teiHeader":{"fileDesc":{"titleStmt":{"title":"Step \"Express an XML schema with ODD\"","author":{"persName":"Charles Riondet","affiliation":"Inria"}},"publicationStmt":{"authority":"Parthenos","availability":{"licence":{"target":"http://creativecommons.org/licenses/by/4.0/","p":"The Creative Commons Attribution 4.0 Unported (CC BY 4.0) Licence applies to this\n       document."}}},"sourceDesc":{"p":"Created from scratch"}},"revisionDesc":{"change":null}},"text":{"body":{"listEvent":{"event":{"type":"researchStep","head":{"type":"stepTitle","lang":"en","content":"Express an XML schema with ODD"},"desc":[{"type":"definition","lang":"en","content":[{"abbr":"ODD"},"stands for ",{"expan":"One Document Does it all"},". It is a TEI-XML\n      conformant specification format that allows one to customize TEI P5 in a literate programming\n      fashion. Any XML schema can be described with ODD."]},{"type":"definition","lang":"fr","content":[{"abbr":"ODD"},"signifie ",{"expan":"One Document Does it all"}," . Il s'agit d'un format\n      de spécification XML-TEI qui permet de personnaliser la TEI P5, suivant les principes de la\n      programmation littéraire. Tout schéma XML peut être décrit avec ODD."]},{"type":"terms","lang":"en","term":[{"key":"XML","source":"standard_list","type":"standard"},{"key":"TEI","source":"standard_list","type":"standard"},{"key":"EAD","source":"standard_list","type":"standard"},{"key":"http://tadirah.dariah.eu/vocab/index.php?tema=35&/modeling","source":"http://tadirah.dariah.eu/","type":"activity","content":"modeling"}]}],"linkGrp":{"type":"generalResources","ref":[{"source":"zotero","target":"Z5SQUJPA","type":"paper"},{"source":"zotero","target":"ZABRV5VD","type":"spec","term":{"key":"TEI","source":"standard_list","type":"standard"}},{"source":"zotero","target":"SS93B7B8","type":"spec","term":{"key":"TEI","source":"standard_list","type":"standard"}},{"source":"zotero","target":"ZE34VR34","type":"spec","term":{"key":"TEI","source":"standard_list","type":"standard"}},{"source":"zotero","target":"UBE86XKI","type":"tutorial","term":{"key":"TEI","source":"standard_list","type":"standard"}},{"source":"zotero","target":"QQT6NQA6","type":"tutorial","term":{"key":"TEI","source":"standard_list","type":"standard"}},{"source":"zotero","target":"IE9EQ2QK","type":"tutorial","term":{"key":"TEI","source":"standard_list","type":"standard"}},{"source":"zotero","target":"69CGH77A","type":"tutorial","term":{"key":"TEI","source":"standard_list","type":"standard"}},{"source":"zotero","target":"XPDZH8WZ","type":"spec","term":{"key":"EAD","source":"standard_list","type":"standard"}},{"source":"zotero","target":"2Z29AVQV","type":"spec","term":{"key":"EAD","source":"standard_list","type":"standard"}},{"source":"github","target":"https://github.com/PARTHENOSWP4/standardsLibrary/tree/master/archivalDescription/EAD/odd","type":"spec","term":[{"key":"EAD","source":"standard_list","type":"standard"},{"key":"TEI","source":"standard_list","type":"standard"}]}]}}}}}},"position":1,"GithubRef":"step_EaXswO_150917"}]}] on [[ssk][1]]
MapperParsingException[failed to parse [TEI.text.body.listEvent.event.desc.content]]; nested: IllegalArgumentException[unknown property [abbr]];
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:329)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:311)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseNonDynamicArray(DocumentParser.java:416)
	at org.elasticsearch.index.mapper.DocumentParser.parseArray(DocumentParser.java:381)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:256)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseNonDynamicArray(DocumentParser.java:416)
	at org.elasticsearch.index.mapper.DocumentParser.parseArray(DocumentParser.java:381)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:256)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:124)
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:309)
	at org.elasticsearch.index.shard.IndexShard.prepareCreate(IndexShard.java:529)
	at org.elasticsearch.index.shard.IndexShard.prepareCreateOnPrimary(IndexShard.java:506)
	at org.elasticsearch.action.index.TransportIndexAction.prepareIndexOperationOnPrimary(TransportIndexAction.java:214)
	at org.elasticsearch.action.index.TransportIndexAction.executeIndexRequestOnPrimary(TransportIndexAction.java:223)
	at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:157)
	at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:66)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:648)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:77)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: unknown property [abbr]
	at org.elasticsearch.index.mapper.core.StringFieldMapper.parseCreateFieldForString(StringFieldMapper.java:366)
	at org.elasticsearch.index.mapper.core.StringFieldMapper.parseCreateField(StringFieldMapper.java:315)
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:321)
	... 43 more
[2018-08-27 10:33:47,901][DEBUG][action.admin.indices.mapping.put] [Ashcan] failed to put mappings on indices [[ssk]], type [scenario]
java.lang.IllegalArgumentException: object mapping [ TEI.text.body.div.desc.content] can't be changed from non-nested to nested
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:512)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.doMerge(RootObjectMapper.java:277)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.merge(RootObjectMapper.java:272)
	at org.elasticsearch.index.mapper.Mapping.merge(Mapping.java:112)
	at org.elasticsearch.index.mapper.DocumentMapper.merge(DocumentMapper.java:376)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:260)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 10:39:10,573][INFO ][cluster.metadata         ] [Ashcan] [ssk] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2018-08-27 10:39:10,608][INFO ][cluster.routing.allocation] [Ashcan] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][4]] ...]).
[2018-08-27 10:39:10,636][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [resource_metadata]
[2018-08-27 10:39:10,645][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:39:10,650][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:39:10,653][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:39:10,657][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:39:10,661][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:39:10,665][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:39:10,671][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [resource]
[2018-08-27 10:39:10,676][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource]
[2018-08-27 10:39:10,680][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [resource]
[2018-08-27 10:39:10,684][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [step_metadata]
[2018-08-27 10:39:10,688][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:39:10,692][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:39:10,695][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:39:10,699][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:39:10,703][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:39:10,706][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step_metadata]
[2018-08-27 10:39:10,710][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [scenario_metadata]
[2018-08-27 10:39:10,715][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:39:10,719][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:39:10,723][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:39:10,727][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:39:10,731][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:39:10,735][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:39:10,740][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [step]
[2018-08-27 10:39:10,745][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,749][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,753][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,756][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,761][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,764][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,770][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,783][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,794][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,801][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,805][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [step]
[2018-08-27 10:39:10,814][INFO ][cluster.metadata         ] [Ashcan] [ssk] create_mapping [scenario]
[2018-08-27 10:39:10,821][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:39:10,831][INFO ][cluster.metadata         ] [Ashcan] [ssk] update_mapping [scenario]
[2018-08-27 10:39:10,847][DEBUG][action.admin.indices.mapping.put] [Ashcan] failed to put mappings on indices [[ssk]], type [scenario]
java.lang.IllegalArgumentException: object mapping [ TEI.text.body.div.desc.content] can't be changed from nested to non-nested
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:508)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.doMerge(RootObjectMapper.java:277)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.merge(RootObjectMapper.java:272)
	at org.elasticsearch.index.mapper.Mapping.merge(Mapping.java:112)
	at org.elasticsearch.index.mapper.DocumentMapper.merge(DocumentMapper.java:376)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:260)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 10:39:30,905][INFO ][node                     ] [Ashcan] stopping ...
[2018-08-27 10:39:30,942][INFO ][node                     ] [Ashcan] stopped
[2018-08-27 10:39:30,942][INFO ][node                     ] [Ashcan] closing ...
[2018-08-27 10:39:30,947][INFO ][node                     ] [Ashcan] closed
[2018-08-27 10:39:38,061][INFO ][node                     ] [Hector] version[2.4.0], pid[54810], build[ce9f0c7/2016-08-29T09:14:17Z]
[2018-08-27 10:39:38,061][INFO ][node                     ] [Hector] initializing ...
[2018-08-27 10:39:38,944][INFO ][plugins                  ] [Hector] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-08-27 10:39:38,962][INFO ][env                      ] [Hector] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [21.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2018-08-27 10:39:38,962][INFO ][env                      ] [Hector] heap size [989.8mb], compressed ordinary object pointers [true]
[2018-08-27 10:39:38,963][WARN ][env                      ] [Hector] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2018-08-27 10:39:40,194][INFO ][node                     ] [Hector] initialized
[2018-08-27 10:39:40,194][INFO ][node                     ] [Hector] starting ...
[2018-08-27 10:39:40,266][INFO ][transport                ] [Hector] publish_address {127.0.0.1:9300}, bound_addresses {[fe80::1]:9300}, {[::1]:9300}, {127.0.0.1:9300}
[2018-08-27 10:39:40,270][INFO ][discovery                ] [Hector] SSK-Cluster/yC9xybPiReadokrsgLhOFQ
[2018-08-27 10:39:43,306][INFO ][cluster.service          ] [Hector] new_master {Hector}{yC9xybPiReadokrsgLhOFQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2018-08-27 10:39:43,317][INFO ][http                     ] [Hector] publish_address {127.0.0.1:9200}, bound_addresses {[fe80::1]:9200}, {[::1]:9200}, {127.0.0.1:9200}
[2018-08-27 10:39:43,317][INFO ][node                     ] [Hector] started
[2018-08-27 10:39:43,347][INFO ][gateway                  ] [Hector] recovered [1] indices into cluster_state
[2018-08-27 10:39:43,659][INFO ][cluster.routing.allocation] [Hector] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][3], [ssk][0], [ssk][4], [ssk][0]] ...]).
[2018-08-27 10:40:30,182][INFO ][cluster.metadata         ] [Hector] [ssk] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2018-08-27 10:40:30,230][INFO ][cluster.routing.allocation] [Hector] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][4], [ssk][4]] ...]).
[2018-08-27 10:40:30,255][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource_metadata]
[2018-08-27 10:40:30,267][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:40:30,274][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:40:30,280][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:40:30,286][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:40:30,292][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:40:30,299][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:40:30,307][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource]
[2018-08-27 10:40:30,315][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:40:30,323][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:40:30,329][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step_metadata]
[2018-08-27 10:40:30,336][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:40:30,344][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:40:30,351][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:40:30,357][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:40:30,363][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:40:30,369][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:40:30,378][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [scenario_metadata]
[2018-08-27 10:40:30,391][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:40:30,401][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:40:30,416][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:40:30,423][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:40:30,441][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:40:30,451][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:40:30,469][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step]
[2018-08-27 10:40:30,484][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,494][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,502][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,527][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,538][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,545][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,552][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,559][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,568][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,576][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,589][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:40:30,597][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [scenario]
[2018-08-27 10:40:30,611][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:40:30,617][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:40:30,631][DEBUG][action.admin.indices.mapping.put] [Hector] failed to put mappings on indices [[ssk]], type [scenario]
java.lang.IllegalArgumentException: object mapping [ TEI.text.body.div.desc.content] can't be changed from nested to non-nested
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:508)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.doMerge(RootObjectMapper.java:277)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.merge(RootObjectMapper.java:272)
	at org.elasticsearch.index.mapper.Mapping.merge(Mapping.java:112)
	at org.elasticsearch.index.mapper.DocumentMapper.merge(DocumentMapper.java:376)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:260)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 10:42:14,353][INFO ][cluster.metadata         ] [Hector] [ssk] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2018-08-27 10:42:14,395][INFO ][cluster.routing.allocation] [Hector] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][0], [ssk][0], [ssk][4]] ...]).
[2018-08-27 10:42:14,419][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource_metadata]
[2018-08-27 10:42:14,430][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:42:14,435][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:42:14,439][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:42:14,444][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:42:14,451][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:42:14,456][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:42:14,461][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource]
[2018-08-27 10:42:14,465][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:42:14,470][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:42:14,474][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step_metadata]
[2018-08-27 10:42:14,479][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:42:14,484][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:42:14,490][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:42:14,494][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:42:14,499][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:42:14,503][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:42:14,508][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [scenario_metadata]
[2018-08-27 10:42:14,512][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:42:14,517][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:42:14,522][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:42:14,527][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:42:14,532][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:42:14,536][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:42:14,542][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step]
[2018-08-27 10:42:14,548][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,554][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,561][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,571][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,576][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,584][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,588][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,599][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,604][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,615][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,622][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:42:14,629][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [scenario]
[2018-08-27 10:42:14,634][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:42:14,646][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:42:14,651][DEBUG][action.admin.indices.mapping.put] [Hector] failed to put mappings on indices [[ssk]], type [scenario]
java.lang.IllegalArgumentException: object mapping [ TEI.text.body.div.desc.content] can't be changed from non-nested to nested
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:512)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.doMerge(RootObjectMapper.java:277)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.merge(RootObjectMapper.java:272)
	at org.elasticsearch.index.mapper.Mapping.merge(Mapping.java:112)
	at org.elasticsearch.index.mapper.DocumentMapper.merge(DocumentMapper.java:376)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:260)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 10:43:17,619][INFO ][cluster.metadata         ] [Hector] [ssk] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2018-08-27 10:43:17,659][INFO ][cluster.routing.allocation] [Hector] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][4]] ...]).
[2018-08-27 10:43:17,680][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource_metadata]
[2018-08-27 10:43:17,690][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:43:17,694][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:43:17,698][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:43:17,702][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:43:17,707][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:43:17,712][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:43:17,716][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource]
[2018-08-27 10:43:17,720][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:43:17,725][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:43:17,730][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step_metadata]
[2018-08-27 10:43:17,734][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:43:17,738][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:43:17,743][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:43:17,748][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:43:17,753][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:43:17,757][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:43:17,762][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [scenario_metadata]
[2018-08-27 10:43:17,766][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:43:17,770][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:43:17,774][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:43:17,779][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:43:17,783][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:43:17,787][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:43:17,793][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step]
[2018-08-27 10:43:17,797][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,802][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,808][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,813][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,820][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,826][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,832][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,837][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,848][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,854][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,863][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:17,871][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [scenario]
[2018-08-27 10:43:17,885][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:43:17,890][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:43:17,903][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:43:17,910][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:43:17,921][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [glossary]
[2018-08-27 10:43:17,929][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [glossary]
[2018-08-27 10:43:17,950][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [glossary]
[2018-08-27 10:43:17,958][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [standard]
[2018-08-27 10:43:18,185][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [standard]
[2018-08-27 10:43:18,629][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [standard]
[2018-08-27 10:43:22,480][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [glossary]
[2018-08-27 10:43:34,645][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario]
[2018-08-27 10:43:34,711][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:43:34,737][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:34,756][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:43:34,781][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:43:35,305][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:43:35,701][DEBUG][action.index             ] [Hector] failed to execute [index {[ssk][step][AWV6jXWT1AEiue2NENZH], source[{"TEI":{"type":"researchStep","id":"step_DoDaAGftRC","teiHeader":{"fileDesc":{"titleStmt":{"title":"step_DoDaAGftRC.xml","author":{"persName":"Haaf Susanne","affiliation":"Berlin-Brandenburg Academy of Sciences and Humanities"}},"publicationStmt":{"authority":"Parthenos","availability":{"licence":{"target":"http://creativecommons.org/licenses/by/4.0/","p":"The Creative Commons Attribution 4.0 Unported (CC BY 4.0) Licence applies to this\n       document."}}},"sourceDesc":{"p":"Created from scratch"}},"revisionDesc":{"change":null}},"text":{"body":{"listEvent":{"event":{"type":"researchStep","head":{"type":"stepTitle","lang":"en","content":"Determination of digitization and annotation guidelines\n      for the research corpus"},"desc":[{"type":"definition","lang":"en","content":["Corpus research should be based on interoperable data,\n      i.e. data that was harmonized with regard to transcription and encoding guidelines. Beforehand\n      the harmonization it is necessary to pick or define proper guidelines. For the encoding of\n      structural phenomena of text, it has become best practice in text processing contexts to apply\n      the tagset provided by the Text Encoding Initiative (TEI-P5). However, the TEI tagset as a\n      whole is broad offering tagging solutions for the most various domains. Hence, in order to\n      achieve unambiguous encoding, it has to be reduced and contoured for its intended application.\n      There are TEI formats published for re-use, e.g. those maintained by the TEI consortium, which\n      can be evaluated for possible re-use rather than creating a new format from scratch. With the\n      DTABf, a TEI format has been proposed, that was customized for the encoding of originally\n      written texts of various text types for the purpose of corpus-based work. Its components are: ",{"list":{"item":["Documentation: Guidelines for text annotation","Documentation: Guidelines for text recognition","Schema: Formal specification in ODD and RNG schemas (for print and manuscript\n        annotation)","Schema: Schematron constraints for quality checks beyond the schema"]}}]},{"type":"terms","lang":"en","term":[{"key":"Discovering","source":"http://tadirah.dariah.eu/","type":"activity"},{"key":"Designing","source":"http://tadirah.dariah.eu/","type":"activity"},{"key":"Meta: Assessing","source":"http://tadirah.dariah.eu/","type":"activity"},{"key":"StandardsSpecifications","source":"http://tadirah.dariah.eu/","type":"object"},{"key":"Standards","source":"NEMO","type":"object"},{"key":"XML","source":"standard_list","type":"standard"},{"key":"TEI","source":"standard_list","type":"standard"}]}],"linkGrp":{"type":"generalResources","ref":[{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/T7672NJ8","type":"specification","content":"DTABf website"},{"source":"github","target":"https://github.com/deutschestextarchiv/dtabf/","type":"specification","content":"DTABf source documents"},{"source":"github","target":"https://github.com/deutschestextarchiv/dtabf/tree/master/schema","type":"specification","content":"DTABf ODDs and Schemas"},{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/DVKJRRVU","type":"paper","content":"Haaf/Geyken/Wiegand (2015)"},{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/ZEZE3HV8","type":"paper","content":"Haaf/Thomas (2017)"},{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/8XCAEJXX","type":"blog","content":"\n       Haaf (2017) "},{"source":"zotero","target":"https://www.zotero.org/groups/427927/items/V6NJ5IBX","type":"website","content":"TEI Customizations"}]}}}}}},"position":3,"GithubRef":"step_DoDaAGftRC"}]}] on [[ssk][1]]
MapperParsingException[failed to parse [TEI.text.body.listEvent.event.desc.content]]; nested: IllegalArgumentException[unknown property [list]];
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:329)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:311)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseNonDynamicArray(DocumentParser.java:416)
	at org.elasticsearch.index.mapper.DocumentParser.parseArray(DocumentParser.java:381)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:256)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseObjectOrField(DocumentParser.java:308)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:328)
	at org.elasticsearch.index.mapper.DocumentParser.parseObject(DocumentParser.java:254)
	at org.elasticsearch.index.mapper.DocumentParser.parseDocument(DocumentParser.java:124)
	at org.elasticsearch.index.mapper.DocumentMapper.parse(DocumentMapper.java:309)
	at org.elasticsearch.index.shard.IndexShard.prepareCreate(IndexShard.java:529)
	at org.elasticsearch.index.shard.IndexShard.prepareCreateOnPrimary(IndexShard.java:506)
	at org.elasticsearch.action.index.TransportIndexAction.prepareIndexOperationOnPrimary(TransportIndexAction.java:214)
	at org.elasticsearch.action.index.TransportIndexAction.executeIndexRequestOnPrimary(TransportIndexAction.java:223)
	at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:157)
	at org.elasticsearch.action.index.TransportIndexAction.shardOperationOnPrimary(TransportIndexAction.java:66)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryPhase.doRun(TransportReplicationAction.java:648)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:279)
	at org.elasticsearch.action.support.replication.TransportReplicationAction$PrimaryOperationTransportHandler.messageReceived(TransportReplicationAction.java:271)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:77)
	at org.elasticsearch.transport.TransportService$4.doRun(TransportService.java:376)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: unknown property [list]
	at org.elasticsearch.index.mapper.core.StringFieldMapper.parseCreateFieldForString(StringFieldMapper.java:366)
	at org.elasticsearch.index.mapper.core.StringFieldMapper.parseCreateField(StringFieldMapper.java:315)
	at org.elasticsearch.index.mapper.FieldMapper.parse(FieldMapper.java:321)
	... 41 more
[2018-08-27 10:52:16,671][INFO ][cluster.metadata         ] [Hector] [ssk] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2018-08-27 10:52:16,706][INFO ][cluster.routing.allocation] [Hector] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][4]] ...]).
[2018-08-27 10:52:16,727][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource_metadata]
[2018-08-27 10:52:16,737][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:16,741][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:16,745][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:16,748][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:16,752][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:16,756][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:16,759][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource]
[2018-08-27 10:52:16,763][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:52:16,768][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:52:16,772][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step_metadata]
[2018-08-27 10:52:16,777][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:16,781][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:16,785][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:16,790][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:16,794][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:16,799][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:16,803][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [scenario_metadata]
[2018-08-27 10:52:16,808][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:16,812][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:16,817][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:16,823][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:16,835][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:16,840][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:16,845][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step]
[2018-08-27 10:52:16,850][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,855][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,861][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,866][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,871][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,876][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,883][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,887][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,893][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:16,905][DEBUG][action.admin.indices.mapping.put] [Hector] failed to put mappings on indices [[ssk]], type [step]
java.lang.IllegalArgumentException: object mapping [ TEI.text.body.listEvent.event.desc.content] can't be changed from non-nested to nested
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:512)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.doMerge(RootObjectMapper.java:277)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.merge(RootObjectMapper.java:272)
	at org.elasticsearch.index.mapper.Mapping.merge(Mapping.java:112)
	at org.elasticsearch.index.mapper.DocumentMapper.merge(DocumentMapper.java:376)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:260)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 10:52:34,234][INFO ][cluster.metadata         ] [Hector] [ssk] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2018-08-27 10:52:34,273][INFO ][cluster.routing.allocation] [Hector] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[ssk][4]] ...]).
[2018-08-27 10:52:34,293][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource_metadata]
[2018-08-27 10:52:34,302][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:34,305][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:34,309][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:34,312][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:34,316][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:34,319][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource_metadata]
[2018-08-27 10:52:34,323][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [resource]
[2018-08-27 10:52:34,326][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:52:34,330][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [resource]
[2018-08-27 10:52:34,334][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step_metadata]
[2018-08-27 10:52:34,337][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:34,341][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:34,345][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:34,348][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:34,352][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:34,356][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step_metadata]
[2018-08-27 10:52:34,359][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [scenario_metadata]
[2018-08-27 10:52:34,364][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:34,368][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:34,372][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:34,376][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:34,380][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:34,384][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [scenario_metadata]
[2018-08-27 10:52:34,388][INFO ][cluster.metadata         ] [Hector] [ssk] create_mapping [step]
[2018-08-27 10:52:34,392][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,396][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,401][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,412][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,417][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,421][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,425][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,430][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,437][INFO ][cluster.metadata         ] [Hector] [ssk] update_mapping [step]
[2018-08-27 10:52:34,442][DEBUG][action.admin.indices.mapping.put] [Hector] failed to put mappings on indices [[ssk]], type [step]
java.lang.IllegalArgumentException: object mapping [ TEI.text.body.listEvent.event.desc.content] can't be changed from non-nested to nested
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:512)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.doMerge(RootObjectMapper.java:277)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.merge(RootObjectMapper.java:272)
	at org.elasticsearch.index.mapper.Mapping.merge(Mapping.java:112)
	at org.elasticsearch.index.mapper.DocumentMapper.merge(DocumentMapper.java:376)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:260)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:20:46,514][DEBUG][action.admin.indices.mapping.put] [Hector] failed to put mappings on indices [[ssk]], type [step]
java.lang.IllegalArgumentException: object mapping [ TEI.text.body.listEvent.event.desc.content] can't be changed from non-nested to nested
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:512)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.doMerge(RootObjectMapper.java:277)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.merge(RootObjectMapper.java:272)
	at org.elasticsearch.index.mapper.Mapping.merge(Mapping.java:112)
	at org.elasticsearch.index.mapper.DocumentMapper.merge(DocumentMapper.java:376)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:260)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:21:02,220][DEBUG][action.admin.indices.mapping.put] [Hector] failed to put mappings on indices [[ssk]], type [step]
java.lang.IllegalArgumentException: object mapping [ TEI.text.body.listEvent.event.desc.content] can't be changed from non-nested to nested
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:512)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:60)
	at org.elasticsearch.index.mapper.object.ObjectMapper.doMerge(ObjectMapper.java:528)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.doMerge(RootObjectMapper.java:277)
	at org.elasticsearch.index.mapper.object.ObjectMapper.merge(ObjectMapper.java:501)
	at org.elasticsearch.index.mapper.object.RootObjectMapper.merge(RootObjectMapper.java:272)
	at org.elasticsearch.index.mapper.Mapping.merge(Mapping.java:112)
	at org.elasticsearch.index.mapper.DocumentMapper.merge(DocumentMapper.java:376)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.applyRequest(MetaDataMappingService.java:260)
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor.execute(MetaDataMappingService.java:230)
	at org.elasticsearch.cluster.service.InternalClusterService.runTasksForExecutor(InternalClusterService.java:468)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:772)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:231)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:194)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:30:53,748][INFO ][node                     ] [Sack] version[2.4.0], pid[55457], build[ce9f0c7/2016-08-29T09:14:17Z]
[2018-08-27 11:30:53,748][INFO ][node                     ] [Sack] initializing ...
[2018-08-27 11:30:54,759][INFO ][plugins                  ] [Sack] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-08-27 11:30:54,777][INFO ][env                      ] [Sack] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [21.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2018-08-27 11:30:54,777][INFO ][env                      ] [Sack] heap size [989.8mb], compressed ordinary object pointers [true]
[2018-08-27 11:30:54,778][WARN ][env                      ] [Sack] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2018-08-27 11:30:55,936][INFO ][node                     ] [Sack] initialized
[2018-08-27 11:30:55,937][INFO ][node                     ] [Sack] starting ...
[2018-08-27 11:30:56,001][INFO ][transport                ] [Sack] publish_address {127.0.0.1:9301}, bound_addresses {[fe80::1]:9301}, {[::1]:9301}, {127.0.0.1:9301}
[2018-08-27 11:30:56,005][INFO ][discovery                ] [Sack] SSK-Cluster/nN4TXxYBSfmFZL0ExVQw3Q
[2018-08-27 11:30:59,827][WARN ][discovery.zen.ping.unicast] [Sack] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9300}]
ReceiveTimeoutTransportException[[][127.0.0.1:9300][internal:discovery/zen/unicast] request_id [3] timed out after [3754ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:30:59,827][WARN ][discovery.zen.ping.unicast] [Sack] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9300}]
ReceiveTimeoutTransportException[[][[::1]:9300][internal:discovery/zen/unicast] request_id [4] timed out after [3754ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:31:00,549][INFO ][cluster.service          ] [Sack] new_master {Sack}{nN4TXxYBSfmFZL0ExVQw3Q}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2018-08-27 11:31:00,563][INFO ][http                     ] [Sack] publish_address {127.0.0.1:9201}, bound_addresses {[fe80::1]:9201}, {[::1]:9201}, {127.0.0.1:9201}
[2018-08-27 11:31:00,563][INFO ][node                     ] [Sack] started
[2018-08-27 11:31:00,586][INFO ][gateway                  ] [Sack] recovered [0] indices into cluster_state
[2018-08-27 11:31:47,304][INFO ][node                     ] [Sack] stopping ...
[2018-08-27 11:31:47,317][INFO ][node                     ] [Sack] stopped
[2018-08-27 11:31:47,317][INFO ][node                     ] [Sack] closing ...
[2018-08-27 11:31:47,321][INFO ][node                     ] [Sack] closed
[2018-08-27 11:31:50,165][INFO ][node                     ] [In-Betweener] version[2.4.0], pid[55478], build[ce9f0c7/2016-08-29T09:14:17Z]
[2018-08-27 11:31:50,165][INFO ][node                     ] [In-Betweener] initializing ...
[2018-08-27 11:31:50,605][INFO ][plugins                  ] [In-Betweener] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-08-27 11:31:50,623][INFO ][env                      ] [In-Betweener] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [21.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2018-08-27 11:31:50,623][INFO ][env                      ] [In-Betweener] heap size [989.8mb], compressed ordinary object pointers [true]
[2018-08-27 11:31:50,624][WARN ][env                      ] [In-Betweener] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2018-08-27 11:31:51,793][INFO ][node                     ] [In-Betweener] initialized
[2018-08-27 11:31:51,794][INFO ][node                     ] [In-Betweener] starting ...
[2018-08-27 11:31:51,860][INFO ][transport                ] [In-Betweener] publish_address {127.0.0.1:9301}, bound_addresses {[fe80::1]:9301}, {[::1]:9301}, {127.0.0.1:9301}
[2018-08-27 11:31:51,865][INFO ][discovery                ] [In-Betweener] SSK-Cluster/k8IQkh1jSrCjyTCL6zY3Tg
[2018-08-27 11:31:55,665][WARN ][discovery.zen.ping.unicast] [In-Betweener] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9300}]
ReceiveTimeoutTransportException[[][[::1]:9300][internal:discovery/zen/unicast] request_id [4] timed out after [3751ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:31:55,665][WARN ][discovery.zen.ping.unicast] [In-Betweener] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9300}]
ReceiveTimeoutTransportException[[][127.0.0.1:9300][internal:discovery/zen/unicast] request_id [3] timed out after [3751ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:31:56,400][INFO ][cluster.service          ] [In-Betweener] new_master {In-Betweener}{k8IQkh1jSrCjyTCL6zY3Tg}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2018-08-27 11:31:56,421][INFO ][http                     ] [In-Betweener] publish_address {127.0.0.1:9201}, bound_addresses {[fe80::1]:9201}, {[::1]:9201}, {127.0.0.1:9201}
[2018-08-27 11:31:56,422][INFO ][node                     ] [In-Betweener] started
[2018-08-27 11:31:56,433][INFO ][gateway                  ] [In-Betweener] recovered [0] indices into cluster_state
[2018-08-27 11:32:29,661][INFO ][node                     ] [In-Betweener] stopping ...
[2018-08-27 11:32:29,675][INFO ][node                     ] [In-Betweener] stopped
[2018-08-27 11:32:29,676][INFO ][node                     ] [In-Betweener] closing ...
[2018-08-27 11:32:29,680][INFO ][node                     ] [In-Betweener] closed
[2018-08-27 11:32:32,544][INFO ][node                     ] [Living Planet] version[2.4.0], pid[55497], build[ce9f0c7/2016-08-29T09:14:17Z]
[2018-08-27 11:32:32,544][INFO ][node                     ] [Living Planet] initializing ...
[2018-08-27 11:32:33,001][INFO ][plugins                  ] [Living Planet] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-08-27 11:32:33,019][INFO ][env                      ] [Living Planet] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [21.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2018-08-27 11:32:33,019][INFO ][env                      ] [Living Planet] heap size [989.8mb], compressed ordinary object pointers [true]
[2018-08-27 11:32:33,020][WARN ][env                      ] [Living Planet] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2018-08-27 11:32:34,182][INFO ][node                     ] [Living Planet] initialized
[2018-08-27 11:32:34,182][INFO ][node                     ] [Living Planet] starting ...
[2018-08-27 11:32:34,252][INFO ][transport                ] [Living Planet] publish_address {127.0.0.1:9301}, bound_addresses {[fe80::1]:9301}, {[::1]:9301}, {127.0.0.1:9301}
[2018-08-27 11:32:34,256][INFO ][discovery                ] [Living Planet] SSK-Cluster/JAyoayDHRo6x0MoGDTwkBA
[2018-08-27 11:32:38,064][WARN ][discovery.zen.ping.unicast] [Living Planet] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9300}]
ReceiveTimeoutTransportException[[][127.0.0.1:9300][internal:discovery/zen/unicast] request_id [2] timed out after [3755ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:32:38,064][WARN ][discovery.zen.ping.unicast] [Living Planet] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9300}]
ReceiveTimeoutTransportException[[][[::1]:9300][internal:discovery/zen/unicast] request_id [3] timed out after [3755ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:32:38,789][INFO ][cluster.service          ] [Living Planet] new_master {Living Planet}{JAyoayDHRo6x0MoGDTwkBA}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2018-08-27 11:32:38,810][INFO ][http                     ] [Living Planet] publish_address {127.0.0.1:9201}, bound_addresses {[fe80::1]:9201}, {[::1]:9201}, {127.0.0.1:9201}
[2018-08-27 11:32:38,810][INFO ][node                     ] [Living Planet] started
[2018-08-27 11:32:38,821][INFO ][gateway                  ] [Living Planet] recovered [0] indices into cluster_state
[2018-08-27 11:34:25,528][INFO ][node                     ] [Living Planet] stopping ...
[2018-08-27 11:34:25,543][INFO ][node                     ] [Living Planet] stopped
[2018-08-27 11:34:25,543][INFO ][node                     ] [Living Planet] closing ...
[2018-08-27 11:34:25,546][INFO ][node                     ] [Living Planet] closed
[2018-08-27 11:34:29,510][INFO ][node                     ] [Blob] version[2.4.0], pid[55542], build[ce9f0c7/2016-08-29T09:14:17Z]
[2018-08-27 11:34:29,511][INFO ][node                     ] [Blob] initializing ...
[2018-08-27 11:34:29,952][INFO ][plugins                  ] [Blob] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-08-27 11:34:29,971][INFO ][env                      ] [Blob] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [21.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2018-08-27 11:34:29,971][INFO ][env                      ] [Blob] heap size [989.8mb], compressed ordinary object pointers [true]
[2018-08-27 11:34:29,972][WARN ][env                      ] [Blob] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2018-08-27 11:34:31,182][INFO ][node                     ] [Blob] initialized
[2018-08-27 11:34:31,182][INFO ][node                     ] [Blob] starting ...
[2018-08-27 11:34:31,253][INFO ][transport                ] [Blob] publish_address {127.0.0.1:9301}, bound_addresses {[fe80::1]:9301}, {[::1]:9301}, {127.0.0.1:9301}
[2018-08-27 11:34:31,258][INFO ][discovery                ] [Blob] SSK-Cluster/3TXDJMhKT62nDb8VVsOcdg
[2018-08-27 11:34:35,061][WARN ][discovery.zen.ping.unicast] [Blob] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9300}]
ReceiveTimeoutTransportException[[][127.0.0.1:9300][internal:discovery/zen/unicast] request_id [2] timed out after [3750ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:34:35,061][WARN ][discovery.zen.ping.unicast] [Blob] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9300}]
ReceiveTimeoutTransportException[[][[::1]:9300][internal:discovery/zen/unicast] request_id [3] timed out after [3750ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:34:35,790][INFO ][cluster.service          ] [Blob] new_master {Blob}{3TXDJMhKT62nDb8VVsOcdg}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2018-08-27 11:34:35,809][INFO ][http                     ] [Blob] publish_address {127.0.0.1:9201}, bound_addresses {[fe80::1]:9201}, {[::1]:9201}, {127.0.0.1:9201}
[2018-08-27 11:34:35,809][INFO ][node                     ] [Blob] started
[2018-08-27 11:34:35,820][INFO ][gateway                  ] [Blob] recovered [0] indices into cluster_state
[2018-08-27 11:39:28,238][INFO ][node                     ] [Blob] stopping ...
[2018-08-27 11:39:28,253][INFO ][node                     ] [Blob] stopped
[2018-08-27 11:39:28,253][INFO ][node                     ] [Blob] closing ...
[2018-08-27 11:39:28,256][INFO ][node                     ] [Blob] closed
[2018-08-27 11:42:12,040][INFO ][node                     ] [Infinity] version[2.4.0], pid[55636], build[ce9f0c7/2016-08-29T09:14:17Z]
[2018-08-27 11:42:12,041][INFO ][node                     ] [Infinity] initializing ...
[2018-08-27 11:42:12,499][INFO ][plugins                  ] [Infinity] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-08-27 11:42:12,517][INFO ][env                      ] [Infinity] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [21.9gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2018-08-27 11:42:12,517][INFO ][env                      ] [Infinity] heap size [989.8mb], compressed ordinary object pointers [true]
[2018-08-27 11:42:12,518][WARN ][env                      ] [Infinity] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
[2018-08-27 11:42:13,724][INFO ][node                     ] [Infinity] initialized
[2018-08-27 11:42:13,724][INFO ][node                     ] [Infinity] starting ...
[2018-08-27 11:42:13,796][INFO ][transport                ] [Infinity] publish_address {127.0.0.1:9301}, bound_addresses {[fe80::1]:9301}, {[::1]:9301}, {127.0.0.1:9301}
[2018-08-27 11:42:13,801][INFO ][discovery                ] [Infinity] SSK-Cluster/bq9iLTK7QLyL3CIURofpzg
[2018-08-27 11:42:17,609][WARN ][discovery.zen.ping.unicast] [Infinity] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9300}]
ReceiveTimeoutTransportException[[][127.0.0.1:9300][internal:discovery/zen/unicast] request_id [2] timed out after [3753ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:42:17,617][WARN ][discovery.zen.ping.unicast] [Infinity] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9300}]
ReceiveTimeoutTransportException[[][[::1]:9300][internal:discovery/zen/unicast] request_id [4] timed out after [3751ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:696)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2018-08-27 11:42:18,338][INFO ][cluster.service          ] [Infinity] new_master {Infinity}{bq9iLTK7QLyL3CIURofpzg}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2018-08-27 11:42:18,358][INFO ][http                     ] [Infinity] publish_address {127.0.0.1:9201}, bound_addresses {[fe80::1]:9201}, {[::1]:9201}, {127.0.0.1:9201}
[2018-08-27 11:42:18,358][INFO ][node                     ] [Infinity] started
[2018-08-27 11:42:18,370][INFO ][gateway                  ] [Infinity] recovered [0] indices into cluster_state
[2018-08-27 15:01:55,695][INFO ][node                     ] [Arize] version[2.4.0], pid[2752], build[ce9f0c7/2016-08-29T09:14:17Z]
[2018-08-27 15:01:55,695][INFO ][node                     ] [Arize] initializing ...
[2018-08-27 15:01:56,683][INFO ][plugins                  ] [Arize] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-08-27 15:01:56,708][INFO ][env                      ] [Arize] using [1] data paths, mounts [[/ (/dev/disk1)]], net usable_space [23.8gb], net total_space [232.5gb], spins? [unknown], types [hfs]
[2018-08-27 15:01:56,708][INFO ][env                      ] [Arize] heap size [989.8mb], compressed ordinary object pointers [true]
[2018-08-27 15:01:56,709][WARN ][env                      ] [Arize] max file descriptors [10240] for elasticsearch process likely too low, consider increasing to at least [65536]
